# Most of the functions docstring using triple-double-quotes were generated by Chat-GPT 3.5

import LexicalAnalyzer

lexiAnalyzer = LexicalAnalyzer.LexicalAnalyzer()
READER = LexicalAnalyzer.reader

ID_TOKEN_TYPE = "ID"

class Parser:
    def __init__ (self):
        # Store the next token returned by the lexical analyzer
        self.csym = ""
        # Stores the token type of the next token
        self.csym_type = ""

        self.follow = {"."}

    def set_csym(self, token):
        """
        Set the current symbol (csym) to the given token.

        Parameters:
        - token: The new value for the current symbol.
        """

        self.csym = token

    def set_csym_type(self, type):
        """
        Set the type of the current symbol (csym_type) to the given type.

        Parameters:
        - type: The new type for the current symbol.
        """

        self.csym_type = type

    def next(self):
        """
        Move to the next token in the lexical analysis and update symbol to be parsed.

        Update the current symbol (csym) and its type (csym_type) accordingly.
        Raise a ValueError if an invalid token is encountered.
        """

        lexiAnalyzer.next()
        token = lexiAnalyzer.get_current_token()
        valid = lexiAnalyzer.get_token_validity()
        if not valid:
            msg = lexiAnalyzer.invalid_token_msg()
            raise ValueError(msg)
        else:
            self.set_csym(token)
            type = lexiAnalyzer.get_token_type()
            self.set_csym_type(type)

    def parse(self):
        """
        Parse the entire program.

        Parse the 'program' keyword.
        Match the program identifier.
        Match the ':' symbol.
        Parse the body of the program.
        Match the '.' symbol.
        """
        self.program()
        self.match(ID_TOKEN_TYPE)
        self.match(":")
        self.body(self.follow)
        #print("test1: " + self.csym)
        self.match(".")
        #print("test1")

    def match(self, sym):
        """
        Match the current symbol with the expected symbol.

        Parameters:
        - sym: The expected symbol or symbol type.

        Raises:
        - AssertionError: If the current symbol does not match the expected symbol.
        """
        assert (self.csym and self.csym in sym) or (self.csym_type == sym), \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected '{sym}'"
        self.next()

    def program(self):
        """
        Parse the 'program' keyword.
        """
        self.match("program")

    def body(self, follow):
        """
        Parse the body.

        If the current symbol is 'bool' or 'int', parse variable declarations.
        Parse statements in the block.
        """
        if (self.csym in ["bool", "int"]):
            self.declarations()
        self.statements(follow)

    # don't need
    def declarations(self):
        """
        Parse a sequence of variable declarations.

        Parse the first declaration.
        Use a loop to handle consecutive declarations of type 'bool' or 'int'.
        """
        self.declaration()

        while (self.csym in ["bool", "int"]):
            self.declaration()

    def declaration(self):
        """
        Parse a declaration statement.

        Ensure the current symbol is 'bool' or 'int', raise an error if not.
        Move to the next token.
        Match an identifier.
        Use a loop to handle consecutive identifiers separated by ','.
        Match the ';' at the end of the declaration.
        """
        assert self.csym in ["bool", "int"], \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected 'bool' or 'int'"
        self.next()
        self.match(ID_TOKEN_TYPE)

        while (self.csym == ","):
            self.next()
            self.match(ID_TOKEN_TYPE)

        self.match(";")

    def statements(self, follow):
        """
        Parse a sequence of statements.

        Parse the first statement.
        Use a loop to handle consecutive statements separated by ';'.
        """
        self.statement(follow.union({";"}))

        while (self.csym == ";"):
            self.next()
            self.statement(follow.union({";"}))

    def statement(self, follow):
        """
        Parse a statement.

        If the current symbol is an identifier, parse an assignment.
        If the current symbol is 'if', parse a conditional statement.
        If the current symbol is 'while', parse an iterative statement.
        If the current symbol is 'print', parse a print statement.
        Otherwise, raise an error with expected set of symbols.
        """
        if (self.csym_type == ID_TOKEN_TYPE):

            self.assignment(follow)
        elif (self.csym == "if"):
            self.conditional(follow)
        elif (self.csym == "while"):
            self.iterative(follow)
        elif (self.csym == "print"):
            self.print_sym(follow)
        else:
            sos = {ID_TOKEN_TYPE, "if", "while", "print"}
            self.expected(sos)

    def expected(self, set_of_symbols):
        """
        Raise an assertion error indicating an unexpected symbol.

        Parameters:
        - set_of_symbols: A set of symbols expected at the current position.

        Raises:
        - AssertionError: Indicates the unexpected symbol and the expected set of symbols.
        """
        raise AssertionError(
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected one of the following {set_of_symbols}"
            )

    def assignment(self, follow):
        """
        Parse an assignment statement.

        Ensure the current symbol is an identifier, raise an error if not.
        Move to the next token by matching the identifier.
        Match the ':=' operator.
        Parse the expression on the right side of the assignment.
        """
        assert self.csym_type == ID_TOKEN_TYPE, \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected an identifier"
        self.match(ID_TOKEN_TYPE)
        self.match(":=")
        self.expr(follow)

    def conditional(self, follow):
        """
        Parse a conditional statement with 'if', indicating an if condition.

        Ensure the current symbol is 'if', raise an error if not.
        Move to the next token by matching 'if'.
        Parse the expression following the 'if' keyword.
        Match the 'then' keyword.
        Parse the body of the 'if' block.
        If there is an 'else' part, move to the next token by matching 'else' and parse the 'else' body.
        Match the 'end' keyword.
        """
        assert self.csym == "if", \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected 'if'"
        self.match("if")
        self.expr(follow)
        self.match("then")
        self.body(follow)
        if (self.csym == "else"):
            self.match("else")
            self.body(follow)
        self.match("end")

    def iterative(self, follow):
        """
        Parse an iterative statement with 'while', indicating a while loop.

        Ensure the current symbol is 'while', raise an error if not.
        Move to the next token by matching 'while'.
        Parse the expression following the 'while' keyword.
        Match the 'do' keyword.
        Parse the body of the loop.
        Match the 'end' keyword.
        """
        assert self.csym == "while", \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected 'while'"
        self.match("while")
        self.expr(follow)
        self.match("do")
        self.body(follow)
        self.match("end")

    def print_sym(self, follow):
        """
        Parse a 'print' statement.

        Ensure the current symbol is 'print', raise an error if not.
        Move to the next token by matching 'print'.
        Parse the expression following the 'print' statement.
        """
        assert self.csym == "print", \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected 'print'"
        self.match("print")
        self.expr(follow)

    def expr(self, follow):
        """
        Parse an expression.

        Call the simple_expr method to parse the first simple expression.
        If the current symbol is a relational operator ('<', '=<', '=', '!=', '>=', '>'),
        move to the next token and parse the next simple expression.
        """
        self.simple_expr(follow.union({"<", "=<", "=", "!=", ">=", ">"}))
        relational_operator = {"<", "=<", "=", "!=", ">=", ">"}
        if self.csym in relational_operator:
            self.next()
            self.simple_expr(follow.union({"<", "=<", "=", "!=", ">=", ">"}))

    def simple_expr(self, follow):
        """
        Parse a simple expression in the overall expression.

        Call the term method to parse the first term.
        Use a loop to handle consecutive terms separated by additive operators ('+', '-', 'or').
        """
        self.term(follow.union({"+", "-", "or"}))
        additive_operator = {"+", "-", "or"}
        while self.csym in additive_operator:
            self.next()
            self.term(follow.union({"+", "-", "or"}))

    def term(self, follow):
        """
        Parse a term in the simple expression.

        Call the factor method to parse the first factor.
        Use a loop to handle consecutive factors separated by multiplicative operators ('*', '/', 'mod', 'and').
        """
        self.factor(follow.union({"*", "/", "mod", "and"}))
        multiplicative_operator = {"*", "/", "mod", "and"}
        while self.csym in multiplicative_operator:
            self.next()
            self.factor(follow.union({"*", "/", "mod", "and"}))

    def factor(self, follow):
        """
        Parse a factor in the expression.

        If the current symbol is '-' or 'not', move to the next token.
        If the current symbol is 'true', 'false', or an integer, call the literal method.
        If the current symbol is an identifier, move to the next token.
        If the current symbol is '(', move to the next token, parse an expression, and match ')'.
        If none of the expected symbols is found, raise an error with expected symbols.
        """
        if (self.csym == "-" or self.csym == "not"):
            self.next()
        if (self.csym in ["true", "false"] or self.csym_type == "NUM"):
            self.literal()
        elif (self.csym_type == ID_TOKEN_TYPE):
            self.next()
        elif (self.csym == "("):
            self.next()
            self.expr(follow)
            self.match(follow.union({")"}))
        else:
            sos = {ID_TOKEN_TYPE, "true", "false", "NUM", "(", "-", "not"}
            self.expected(sos)

    def literal(self):
        """
        Ensure the current symbol is either "true", "false", or an integer.
        If not, raise an assertion error.
        If the symbol is an integer, move to the next token.
        Otherwise, call the boolean_literal method.
        """
        assert self.csym in ["true", "false"] or self.csym_type == "NUM", \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected 'true', 'false', or an integer"
        if (self.csym_type == "NUM"):
            self.next()
        else:
            self.boolean_literal()

    def boolean_literal(self):
        """
        Ensure the current symbol is either "true" or "false".
        If not, raise an assertion error.
        Then, move to the next token.
        """
        assert self.csym in ["true", "false"], \
            f"{lexiAnalyzer.get_token_position()}:>>>>> Bad symbol '{self.csym}':  expected a 'true' or 'false'"
        self.next()

    def reset(self):
        """
        Restore instance variables of Parser to default state.

        No return value.
        """
        global lexiAnalyzer

        lexiAnalyzer.reset()

        self.csym = ""
        self.csym_type = ""

    def read_file(self, user_input):
        """
        Gets user input for a file to read, opens the
        file, and makes sure it is syntactically correct.

        Returns:
            - (Boolean) True if the file is syntactically correct
            - (String) Assertion error message string if file is not syntactically correct
        """

        global lexiAnalyzer, READER

        # Try opening the file.
        # If valid and file was successfully opened, value is 1.
        # If invalid and file was not opened, value is 0.
        valid_file = READER.open_file(user_input)

        if (valid_file == 1):
            # Read the first character from the file.
            READER.next_char()
            # Read the first token from the file.
            self.next()

            while(lexiAnalyzer.get_token_type() != "end-of-text"):
                try:
                    self.parse()
                    print(f"Concluded syntax analysis on {user_input}")

                except AssertionError as e:
                    # If an assertion error occurs, the syntax is not valid
                    error_msg = user_input + ":" + str(e)
                    self.reset()
                    return error_msg

                except ValueError as e:
                    # If a value error occurred, the lexical analyzer encountered a token that is invalid to the grammar
                    error_msg = user_input + ":" + str(e)
                    self.reset()
                    return error_msg

            self.reset()

            # If there was no error, then the file is syntactically correct
            return True

    def prompt_user(self):
        """
        Prompts user for a file to parse.
        Once user inputs valid file, the file is
        parsed.

        The user can quit at any time they receive a
        prompt by typing 'quit' or 'exit' and
        pressing enter.

        Note: This is the same function from FileReader.py and
        LexicalAnalyzer.py. By implementing it in this class
        (Parser), it uses this classes read_file()
        function rather than the read_file() function contained
        in FileReader.py

        i.e. This is overwriting the prompt_user() method
        contained by the other programs

        No return value

        Prints the value returned by Parser's read_file()
        """
        while(True):
            user_input = input(">>> Enter a file name, or type 'quit' or 'exit' to exit: ")
            if(user_input in ["quit", "exit"]):
                print("Program terminating...")
                break
            else:
                # Process file for parsing
                print(self.read_file(user_input))

if __name__ == "__main__":
    # Create an instance of the Parser class
    par = Parser()

    par.prompt_user()